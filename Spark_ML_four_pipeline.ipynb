{"cells":[{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.feature import HashingTF, Tokenizer\n\n# Prepare training documents from a list of (id, text, label) tuples.\ntraining = spark.createDataFrame([\n    (0, \"a b c d e spark duo fuxi this is cool mike\", 1.0),\n    (1, \"b d f i hate mike hate data \", 0.0),\n    (2, \"spark i love spark ddd example hadoop\", 1.0),\n    (3, \"i love coding and ml\", 0.0),\n   (4, \"i want to move fast\", 1.0), \n   (5, \"Mike like student to ask question\", 1.0),\n   (6, \"Mike hate people to ask hwo to import spark URL\", 0.0)\n], [\"id\", \"text\", \"label\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["display(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>text</th><th>label</th></tr></thead><tbody><tr><td>0</td><td>a b c d e spark duo fuxi this is cool mike</td><td>1.0</td></tr><tr><td>1</td><td>b d f i hate mike hate data </td><td>0.0</td></tr><tr><td>2</td><td>spark i love spark ddd example hadoop</td><td>1.0</td></tr><tr><td>3</td><td>i love coding and ml</td><td>0.0</td></tr><tr><td>4</td><td>i want to move fast</td><td>1.0</td></tr><tr><td>5</td><td>Mike like student to ask question</td><td>1.0</td></tr><tr><td>6</td><td>Mike hate people to ask hwo to import spark URL</td><td>0.0</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"code","source":["# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\ntokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\n\n# now build the estimator 面试时常会问的问题，就是 你调优LR 的时候，你用了什么参数？\nlr = LogisticRegression(maxIter=10, regParam=0.001)\n\n# build a pipeline here\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n#piepline.saveAs(\"location\")\n#pipeline.load(\"location\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["preprocess_model = pipeline.fit(training)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# Fit the pipeline to training documents.\nmodel = pipeline.fit(training)\n# model.saveAs(directory)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Prepare test documents, which are unlabeled (id, text) tuples.\ntest = spark.createDataFrame([\n    (4, \"spark i j k\"),\n    (5, \"l m n\"),\n    (6, \"spark hadoop spark\"),\n    (7, \"apache hadoop\")\n], [\"id\", \"text\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["display(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>text</th></tr></thead><tbody><tr><td>4</td><td>spark i j k</td></tr><tr><td>5</td><td>l m n</td></tr><tr><td>6</td><td>spark hadoop spark</td></tr><tr><td>7</td><td>apache hadoop</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Make predictions on test documents and print columns of interest.\nprediction = model.transform(test)\nselected = prediction.select(\"id\", \"text\", \"probability\", \"prediction\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["hash_results = preprocess_model.transform(test)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["display(hash_results)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>text</th><th>words</th><th>features</th><th>rawPrediction</th><th>probability</th><th>prediction</th></tr></thead><tbody><tr><td>4</td><td>spark i j k</td><td>List(spark, i, j, k)</td><td>List(0, 262144, List(20197, 24417, 227520, 234657), List(1.0, 1.0, 1.0, 1.0))</td><td>List(1, 2, List(), List(-1.021302773370314, 1.021302773370314))</td><td>List(1, 2, List(), List(0.2647737137672841, 0.7352262862327159))</td><td>1.0</td></tr><tr><td>5</td><td>l m n</td><td>List(l, m, n)</td><td>List(0, 262144, List(18910, 100743, 213302), List(1.0, 1.0, 1.0))</td><td>List(1, 2, List(), List(-0.5051253893484876, 0.5051253893484876))</td><td>List(1, 2, List(), List(0.37633694143148283, 0.6236630585685172))</td><td>1.0</td></tr><tr><td>6</td><td>spark hadoop spark</td><td>List(spark, hadoop, spark)</td><td>List(0, 262144, List(155117, 234657), List(1.0, 2.0))</td><td>List(1, 2, List(), List(-3.3943146193514866, 3.3943146193514866))</td><td>List(1, 2, List(), List(0.032473620122634224, 0.9675263798773658))</td><td>1.0</td></tr><tr><td>7</td><td>apache hadoop</td><td>List(apache, hadoop)</td><td>List(0, 262144, List(66695, 155117), List(1.0, 1.0))</td><td>List(1, 2, List(), List(-2.187390745427375, 2.187390745427375))</td><td>List(1, 2, List(), List(0.1008885327842177, 0.8991114672157823))</td><td>1.0</td></tr></tbody></table></div>"]}}],"execution_count":10},{"cell_type":"code","source":["display(selected)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>text</th><th>probability</th><th>prediction</th></tr></thead><tbody><tr><td>4</td><td>spark i j k</td><td>List(1, 2, List(), List(0.2647737137672841, 0.7352262862327159))</td><td>1.0</td></tr><tr><td>5</td><td>l m n</td><td>List(1, 2, List(), List(0.37633694143148283, 0.6236630585685172))</td><td>1.0</td></tr><tr><td>6</td><td>spark hadoop spark</td><td>List(1, 2, List(), List(0.032473620122634224, 0.9675263798773658))</td><td>1.0</td></tr><tr><td>7</td><td>apache hadoop</td><td>List(1, 2, List(), List(0.1008885327842177, 0.8991114672157823))</td><td>1.0</td></tr></tbody></table></div>"]}}],"execution_count":11},{"cell_type":"code","source":["for row in selected.collect():\n    rid, text, prob, prediction = row\n    print(\"(%d, %s) --> prob=%s, prediction=%f\" % (rid, text, str(prob), prediction))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(4, spark i j k) --&gt; prob=[0.2647737137672841,0.7352262862327159], prediction=1.000000\n(5, l m n) --&gt; prob=[0.37633694143148283,0.6236630585685172], prediction=1.000000\n(6, spark hadoop spark) --&gt; prob=[0.032473620122634224,0.9675263798773658], prediction=1.000000\n(7, apache hadoop) --&gt; prob=[0.1008885327842177,0.8991114672157823], prediction=1.000000\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.feature import OneHotEncoder, StringIndexer\n \ndf = spark.createDataFrame([\n\t(0, \"a\"),\n\t(1, \"b\"),\n\t(2, \"c\"),\n\t(3, \"a\"),\n\t(4, \"a\"),\n\t(5, \"c\")\n], [\"id\", \"category\"])\n \nstringIndexer = StringIndexer(inputCol=\"category\", outputCol=\"categoryIndex\")\nmodel = stringIndexer.fit(df)\nindexed = model.transform(df)\n# indexed.show()\n \nencoder = OneHotEncoder(inputCol=\"categoryIndex\", outputCol=\"categoryVec\")\nencoded = encoder.transform(indexed)\nencoded.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+-------------+-------------+\n id|category|categoryIndex|  categoryVec|\n+---+--------+-------------+-------------+\n  0|       a|          0.0|(2,[0],[1.0])|\n  1|       b|          2.0|    (2,[],[])|\n  2|       c|          1.0|(2,[1],[1.0])|\n  3|       a|          0.0|(2,[0],[1.0])|\n  4|       a|          0.0|(2,[0],[1.0])|\n  5|       c|          1.0|(2,[1],[1.0])|\n+---+--------+-------------+-------------+\n\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":14}],"metadata":{"name":"Spark_ML_four_pipeline","notebookId":235873308282434},"nbformat":4,"nbformat_minor":0}
